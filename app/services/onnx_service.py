"""
ONNX Model Export Service
è‡ªåŠ¨å°†è®­ç»ƒå¥½çš„scikit-learnæ¨¡å‹è½¬æ¢å¹¶ä¿å­˜ä¸ºONNXæ ¼å¼
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Any, Optional, Dict, Union
import logging

logger = logging.getLogger(__name__)

class ONNXService:
    def __init__(self, save_directory: str = "models"):
        """
        åˆå§‹åŒ–ONNXæœåŠ¡
        
        Args:
            save_directory: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        # Handle exe environment - use absolute path
        if getattr(sys, 'frozen', False):
            # Running as exe
            exe_dir = os.path.dirname(sys.executable)
            self.save_directory = os.path.join(exe_dir, save_directory)
        else:
            # Running as script
            self.save_directory = os.path.abspath(save_directory)
        
        self.ensure_directory_exists()
        
    def ensure_directory_exists(self):
        """ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨"""
        try:
            if not os.path.exists(self.save_directory):
                os.makedirs(self.save_directory)
                logger.info(f"Created directory: {self.save_directory}")
        except PermissionError:
            # Fallback to user documents folder
            user_docs = os.path.expanduser("~/Documents/SpectroEase")
            self.save_directory = os.path.join(user_docs, "models")
            if not os.path.exists(self.save_directory):
                os.makedirs(self.save_directory)
                logger.info(f"Created fallback directory: {self.save_directory}")
    
    def can_export_to_onnx(self, model: Any) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ä»¥å¯¼å‡ºåˆ°ONNXæ ¼å¼
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            
        Returns:
            bool: æ˜¯å¦å¯ä»¥å¯¼å‡º
        """
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ¨¡å‹ç±»å‹
            model_type = type(model).__name__
            
            # æ”¯æŒçš„æ¨¡å‹ç±»å‹åˆ—è¡¨
            supported_models = [
                'LogisticRegression',
                'RandomForestClassifier',
                'RandomForestRegressor',
                'SVC',
                'SVR',
                'KNeighborsClassifier',
                'KNeighborsRegressor',
                'DecisionTreeClassifier',
                'DecisionTreeRegressor',
                'GradientBoostingClassifier',
                'GradientBoostingRegressor',
                'LinearRegression',
                'Ridge',
                'Lasso',
                'ElasticNet',
                'MLPClassifier',
                'MLPRegressor',
                'AdaBoostClassifier',
                'AdaBoostRegressor',
                'ExtraTreesClassifier',
                'ExtraTreesRegressor',
                'GaussianNB',
                'MultinomialNB',
                'BernoulliNB'
            ]
            
            if model_type in supported_models:
                return True
            
            # æ£€æŸ¥é›†æˆæ¨¡å‹ï¼ˆå¦‚VotingClassifierç­‰ï¼‰
            if hasattr(model, 'estimators_'):
                return True
                
            logger.warning(f"Model type {model_type} may not be supported for ONNX export")
            return False
            
        except Exception as e:
            logger.error(f"Error checking ONNX compatibility: {e}")
            return False
    
    def export_model_to_onnx(self, model: Any, X_sample: np.ndarray, 
                           model_name: str = None, method: str = None) -> Optional[str]:
        """
        å°†æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_sample: æ ·æœ¬æ•°æ®ï¼Œç”¨äºæ¨æ–­è¾“å…¥å½¢çŠ¶
            model_name: æ¨¡å‹åç§°
            method: è®­ç»ƒMethodåç§°
            
        Returns:
            str: ä¿å­˜çš„ONNXæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            print("ğŸ”§ å°è¯•ONNXæ ¼å¼å¯¼å‡º...")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒONNXå¯¼å‡º
            if not self.can_export_to_onnx(model):
                print(f"âš ï¸ æ¨¡å‹ç±»å‹ {type(model).__name__} ä¸æ”¯æŒONNXå¯¼å‡º")
                return None
            
            # å°è¯•å¯¼å…¥skl2onnxåº“
            try:
                from skl2onnx import convert_sklearn
                from skl2onnx.common.data_types import FloatTensorType
            except ImportError:
                print("âš ï¸ skl2onnxåº“æœªå®‰è£…ï¼Œæ— æ³•å¯¼å‡ºONNXæ ¼å¼")
                print("ğŸ’¡ è¯·å®‰è£…: pip install skl2onnx onnxruntime")
                return None
            
            # æ¨æ–­è¾“å…¥å½¢çŠ¶
            if len(X_sample.shape) == 1:
                initial_type = [('float_input', FloatTensorType([None, 1]))]
            else:
                n_features = X_sample.shape[1]
                initial_type = [('float_input', FloatTensorType([None, n_features]))]
            
            # è½¬æ¢æ¨¡å‹
            try:
                onnx_model = convert_sklearn(model, initial_types=initial_type)
                
                # ç”Ÿæˆæ–‡ä»¶å
                if model_name is None:
                    model_name = type(model).__name__
                
                if method:
                    filename = f"{method}_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.onnx"
                else:
                    filename = f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.onnx"
                
                filepath = os.path.join(self.save_directory, filename)
                
                # ä¿å­˜ONNXæ¨¡å‹
                with open(filepath, 'wb') as f:
                    f.write(onnx_model.SerializeToString())
                
                print(f"âœ… ONNXæ¨¡å‹ä¿å­˜æˆåŠŸ: {filepath}")
                return filepath
                
            except Exception as e:
                print(f"âŒ ONNXè½¬æ¢å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None
            
        except Exception as e:
            print(f"âŒ ONNXå¯¼å‡ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def auto_save_model(self, model: Any, X_sample: np.ndarray, 
                      model_name: str = None, method: str = None,
                      evaluation_results: Dict = None) -> Optional[str]:
        """
        è‡ªåŠ¨ä¿å­˜æ¨¡å‹ä¸ºpickleæ ¼å¼ï¼ˆé’ˆå¯¹è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ä¼˜åŒ–ï¼‰
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_sample: æ ·æœ¬æ•°æ®
            model_name: æ¨¡å‹åç§°
            method: è®­ç»ƒMethodåç§°
            evaluation_results: è¯„ä¼°ç»“æœ
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # ä½¿ç”¨printè€Œä¸æ˜¯logger.infoï¼Œé¿å…é˜»å¡UI
            print("ğŸš€ å¼€å§‹è‡ªåŠ¨ä¿å­˜æ¨¡å‹...")
            
            # ç›´æ¥ä½¿ç”¨pickleæ ¼å¼ï¼ˆå¿«é€Ÿä¸”é€‚åˆè¾¹ç¼˜è®¾å¤‡ï¼‰
            print("ğŸ’¾ ä½¿ç”¨pickleæ ¼å¼ä¿å­˜ï¼ˆé€‚åˆè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼‰...")
            pickle_path = self.save_model_as_pickle(model, X_sample, model_name, method, evaluation_results)
            
            if pickle_path:
                print(f"âœ… Pickleæ ¼å¼ä¿å­˜æˆåŠŸ: {pickle_path}")
                # ä¿å­˜æ¨¡å‹ä¿¡æ¯
                self.save_model_info(pickle_path, model, method, evaluation_results)
                return pickle_path
            else:
                print("âŒ æ¨¡å‹ä¿å­˜å¤±è´¥")
                return None
                    
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def save_model_info(self, model_path: str, model: Any, method: str = None, 
                       evaluation_results: Dict = None):
        """
        ä¿å­˜æ¨¡å‹ç›¸å…³ä¿¡æ¯åˆ°æ–‡æœ¬æ–‡ä»¶
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.onnx æˆ– .pklï¼‰
            model: Originalæ¨¡å‹
            method: è®­ç»ƒMethod
            evaluation_results: è¯„ä¼°ç»“æœ
        """
        try:
            # ç”Ÿæˆä¿¡æ¯æ–‡ä»¶è·¯å¾„ï¼Œæ­£ç¡®å¤„ç†.pklå’Œ.onnxæ–‡ä»¶
            if model_path.endswith('.onnx'):
                info_path = model_path.replace('.onnx', '_info.txt')
                model_file_label = "ONNX File"
            elif model_path.endswith('.pkl'):
                info_path = model_path.replace('.pkl', '_info.txt')
                model_file_label = "Model File"
            else:
                # é»˜è®¤å¤„ç†
                base_name = os.path.splitext(model_path)[0]
                info_path = f"{base_name}_info.txt"
                model_file_label = "Model File"
            
            with open(info_path, 'w', encoding='utf-8') as f:
                f.write(f"Model Information\n")
                f.write(f"=================\n\n")
                f.write(f"Export Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Model Type: {type(model).__name__}\n")
                f.write(f"Training Method: {method or 'Unknown'}\n")
                f.write(f"{model_file_label}: {os.path.basename(model_path)}\n\n")
                
                if hasattr(model, 'task_type'):
                    f.write(f"Task Type: {model.task_type}\n")
                
                if hasattr(model, 'n_features_in_'):
                    f.write(f"Number of Features: {model.n_features_in_}\n")
                
                if hasattr(model, 'classes_'):
                    f.write(f"Number of Classes: {len(model.classes_)}\n")
                    f.write(f"Classes: {list(model.classes_)}\n")
                
                # ä¿å­˜è¯„ä¼°ç»“æœ
                if evaluation_results:
                    f.write(f"\nEvaluation Results:\n")
                    f.write(f"------------------\n")
                    for key, value in evaluation_results.items():
                        if key not in ['Confusion Matrix', 'Classification Report']:
                            if isinstance(value, float):
                                f.write(f"{key}: {value:.4f}\n")
                            else:
                                f.write(f"{key}: {value}\n")
                
                # ä¿å­˜æ¨¡å‹Parameters
                if hasattr(model, 'get_params'):
                    f.write(f"\nModel Parameters:\n")
                    f.write(f"----------------\n")
                    params = model.get_params()
                    for key, value in params.items():
                        f.write(f"{key}: {value}\n")
            
            logger.info(f"Model info saved to: {info_path}")
            
        except Exception as e:
            logger.error(f"Failed to save model info: {e}")
    
    def save_model_as_pickle(self, model: Any, X_sample: np.ndarray, 
                           model_name: str = None, method: str = None,
                           evaluation_results: Dict = None) -> Optional[str]:
        """
        ä½¿ç”¨pickleæ ¼å¼ä¿å­˜æ¨¡å‹ï¼ˆé’ˆå¯¹è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ä¼˜åŒ–ï¼‰
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_sample: æ ·æœ¬æ•°æ®
            model_name: æ¨¡å‹åç§°
            method: è®­ç»ƒMethodåç§°
            evaluation_results: è¯„ä¼°ç»“æœ
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            import pickle
            
            # ç”Ÿæˆæ–‡ä»¶å
            if model_name is None:
                model_name = type(model).__name__
            
            if method:
                filename = f"{method}_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            else:
                filename = f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            
            filepath = os.path.join(self.save_directory, filename)
            
            # æ„å»ºéƒ¨ç½²åŒ…ï¼ˆåŒ…å«è¾¹ç¼˜è®¾å¤‡éœ€è¦çš„æ‰€æœ‰ä¿¡æ¯ï¼‰
            deployment_package = {
                # æ ¸å¿ƒæ¨¡å‹
                'model': model,
                
                # æ¨¡å‹å…ƒæ•°æ®
                'model_name': model_name,
                'model_type': type(model).__name__,
                'method': method,
                'timestamp': datetime.now().isoformat(),
                
                # è¾“å…¥è¾“å‡ºè§„æ ¼
                'input_shape': X_sample.shape,
                'n_features': X_sample.shape[1] if len(X_sample.shape) > 1 else X_sample.shape[0],
                'n_samples_trained': X_sample.shape[0],
                
                # æ¨¡å‹å±æ€§ï¼ˆç”¨äºæ¨ç†éªŒè¯ï¼‰
                'model_attributes': {}
            }
            
            # æå–æ¨¡å‹å…³é”®å±æ€§ï¼ˆç”¨äºè¾¹ç¼˜è®¾å¤‡éªŒè¯ï¼‰
            if hasattr(model, 'classes_'):
                deployment_package['model_attributes']['classes'] = model.classes_.tolist()
                deployment_package['model_attributes']['n_classes'] = len(model.classes_)
            
            if hasattr(model, 'n_features_in_'):
                deployment_package['model_attributes']['n_features_in'] = model.n_features_in_
            
            if hasattr(model, 'feature_names_in_'):
                deployment_package['model_attributes']['feature_names'] = model.feature_names_in_.tolist()
            
            # æ·»åŠ è¯„ä¼°ç»“æœï¼ˆç”¨äºè´¨é‡ç›‘æ§ï¼‰
            if evaluation_results:
                # åªä¿ç•™æ•°å€¼å‹æŒ‡æ ‡ï¼Œæ’é™¤å¤§å‹å¯¹è±¡
                deployment_package['performance_metrics'] = {
                    k: v for k, v in evaluation_results.items()
                    if isinstance(v, (int, float, str)) and k not in ['Confusion Matrix', 'Classification Report']
                }
            
            # ä¿å­˜æ¨¡å‹
            print(f"ğŸ’¾ ä¿å­˜pickleæ¨¡å‹åˆ°: {filepath}")
            print(f"ğŸ“¦ éƒ¨ç½²åŒ…å†…å®¹: model + metadata + performance_metrics")
            
            with open(filepath, 'wb') as f:
                pickle.dump(deployment_package, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
            file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB
            print(f"âœ… Model successfully saved as pickle: {filepath}")
            print(f"ğŸ“Š File size: {file_size:.2f} MB")
            print(f"ğŸ¯ Ready for edge device deployment")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ Pickleä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None 